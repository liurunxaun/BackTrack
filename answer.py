from utils import llm_api as llm

def generate_answer(question, reference=""):
    """
    输入：用户的问题，推理出的意图和目的实体
    处理过程：完善query，交给大模型
    输出：最终答案
    """

    query = f"""
    我在做知识问答。
    用户输入了问题：{question}
    我可以提供给你一些我在我的知识图谱中推理检索得到的参考内容：{reference}
    在参考内容中有两部分，一个是条件，一个是目的。条件是指用户输入的问题中的已知条件。目的是指问题中想问的东西。
    也许我提供的参考内容中的条件和目的并不能涵盖用户输入的问题所包含的语义上的条件和目的，你可以根据参考内容自己继续推理。
    生成答案，并返回。
    生成的答案中不要透露我给你输入了参考内容。
    """

    return llm.spark_4_0(query)